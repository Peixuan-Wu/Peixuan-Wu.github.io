# GPU 是如何工作的 
> [参考自B站_从上帝时间看GPU](https://www.bilibili.com/video/BV1P44y1V7bu/?spm_id_from=333.788.recommend_more_video.4)

## 图像流水线的基础
显示器的基本单元是像素 包含红绿蓝三个元色 也就是对应RGB的三个分量。

三个分量的取值范围是0-8bit(generally),因此三种颜色组合起来即是 256*256*256 共16777216种颜色。

在计算机的内存中，有一个区域叫做帧缓存区域，其中存储了显示图形的每一个像素。

由于每一个像素是由三个八位原色组成，因此帧缓存有三个字节来存储一个像素的原色

又因为计算机(32bit)更倾向于存储32位也就是4个字节的内存单元，因此帧缓存以连续存储4个字节的内存单元来表示每一个像素点。那么第四个字节存书了什么呢？它会用来存储像素的透明度(alpha)。虽然输出到显示器的时候这个透明度信息会被忽略。 

帧缓存上的信息会通过显卡(graphic card)转化输出到显示器上。 这时**显卡**是没有计算能力的，之时图像的搬运工。
 
如果我们想要将图像的亮度翻倍，那么我们需要将RGB三个分量都*2，这一步能够通过CPU来完成，但是会占用大量的处理能力。 所以可以单独使用一个处理器PU来处理相同的工作。

如果操作的算法固定，那么我们只需要设置不同的参数就可以完成，但是操作需要灵活多变就需要挂上一程序，这个程序就是shader， 并且因为shader处理的事像素，这个程序又叫做**pixel shader**.

一个可以绑上shader的单元就被称为**可编程流水线单元(programmable pipline unit)**。
每个 pixel shader 单入单出

那么shader 如何读取单个像素进行处理呢最后在存入帧缓存呢，首先我们输入的图像叫做**纹理(texture)**，从单个坐标提取出像素发送给shader 这一步并不需要shader自己来完成，而是有专门的硬件来处理。

但是当我们输入的图像不再是单一的像素点构成的平面，而是一个三维立体图形呢？
这些三维立体图形通常是有简单图形构成的例如: 点、线、三角形

那么这些三角形怎么和像素搭上关系呢，在图像进入pixel shader 之前需要吧三角形所覆盖区域的像素填上，这个环节叫做**光栅化(rasterize)**,这个环节通常算法固定，不可编程，称为**固定流水线单元(fixed-pipline unit)** 

除此之外，几何存在前后遮挡的关系，那么如何决定哪些像素显示，哪些像素不显示呢，这就需要在pixel shader 之后加入加入一个叫**output merger** 的环节，会做深度判断，这也是固定流水单元，

几何都有顶点，存放顶点又 **vertec buffer**  和 **index buff(存储vertext 的连接顺序)**

在光栅化之前我们还需要**图元组装单元(primitive assembler)**将顶点组成一个个三角形，裁剪显示器外的部分，再送入光栅化程序。

同一个几何可以摆放不同位置， 不同角度，这时index buffer 不变 而vertex buffer 需要变化，三个变换
*三个矩阵4*4，
>
1.world matrix
2.view matrix
3.projection matrix 视野的宽窄

这一部可以通过一个硬件T&L来完成，早期是固定流水线单元，但后来进化到可编程的方式，
每一个顶点通过一个shader  ，也就是 **vertex shader**

每个vertex shader 也是单入单出


这就是一条基本的图形流水线，
有可编程的单元，也有不可编程的单元，
由专门的GPU来做这一步工作

CPU更喜欢对少量数据做复杂运算或逻辑处理
而GPU跟喜欢对大量数据做简单的并行运算。



